{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gp:AOqpTOH5OkwJH-nRT4nopD_JNTIYpWs1xWzOsFE-pn7...</td>\n",
       "      <td>Charles Green</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>Ugh! After years of using this app, I am so ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.9.0.2</td>\n",
       "      <td>2021-02-10 16:21:44</td>\n",
       "      <td>90% of the app is completely free, including a...</td>\n",
       "      <td>2021-02-11 09:29:42</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gp:AOqpTOH2VEhd1ldAR1zxGzjJEIa37fCBgY9S3sqe_TE...</td>\n",
       "      <td>Matt Van Der Schyff</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-sMd4wLr...</td>\n",
       "      <td>originally gave this a 2 star but I think it o...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>5.9.0.2</td>\n",
       "      <td>2021-02-04 05:35:28</td>\n",
       "      <td>We are unaware of any issues with setting remi...</td>\n",
       "      <td>2021-02-04 09:08:06</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gp:AOqpTOFZ-MWENdh24H_g0qGDAVUkrdFEJoNaYudcwe2...</td>\n",
       "      <td>Don White</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-3dOQZya...</td>\n",
       "      <td>January 2021: In short..I'm done, and moving o...</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>5.7.0.20</td>\n",
       "      <td>2021-01-15 14:25:27</td>\n",
       "      <td>We're are doing our best to fix any issues and...</td>\n",
       "      <td>2021-01-18 14:11:54</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewId             userName  \\\n",
       "0  gp:AOqpTOH5OkwJH-nRT4nopD_JNTIYpWs1xWzOsFE-pn7...        Charles Green   \n",
       "1  gp:AOqpTOH2VEhd1ldAR1zxGzjJEIa37fCBgY9S3sqe_TE...  Matt Van Der Schyff   \n",
       "2  gp:AOqpTOFZ-MWENdh24H_g0qGDAVUkrdFEJoNaYudcwe2...            Don White   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "1  https://play-lh.googleusercontent.com/-sMd4wLr...   \n",
       "2  https://play-lh.googleusercontent.com/-3dOQZya...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Ugh! After years of using this app, I am so ve...      1              3   \n",
       "1  originally gave this a 2 star but I think it o...      1             72   \n",
       "2  January 2021: In short..I'm done, and moving o...      1            186   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0              5.9.0.2  2021-02-10 16:21:44   \n",
       "1              5.9.0.2  2021-02-04 05:35:28   \n",
       "2             5.7.0.20  2021-01-15 14:25:27   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0  90% of the app is completely free, including a...  2021-02-11 09:29:42   \n",
       "1  We are unaware of any issues with setting remi...  2021-02-04 09:08:06   \n",
       "2  We're are doing our best to fix any issues and...  2021-01-18 14:11:54   \n",
       "\n",
       "       sortOrder      appId  \n",
       "0  most_relevant  com.anydo  \n",
       "1  most_relevant  com.anydo  \n",
       "2  most_relevant  com.anydo  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='score', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the scores into negative, neutral and positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(rating) : \n",
    "    if (rating == 1 )|(rating == 2) : \n",
    "        return 0 \n",
    "    elif (rating == 3) : \n",
    "        return 1 \n",
    "    elif (rating >= 4) : \n",
    "        return 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df.score.apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gp:AOqpTOH5OkwJH-nRT4nopD_JNTIYpWs1xWzOsFE-pn7...</td>\n",
       "      <td>Charles Green</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>Ugh! After years of using this app, I am so ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.9.0.2</td>\n",
       "      <td>2021-02-10 16:21:44</td>\n",
       "      <td>90% of the app is completely free, including a...</td>\n",
       "      <td>2021-02-11 09:29:42</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gp:AOqpTOH2VEhd1ldAR1zxGzjJEIa37fCBgY9S3sqe_TE...</td>\n",
       "      <td>Matt Van Der Schyff</td>\n",
       "      <td>https://play-lh.googleusercontent.com/-sMd4wLr...</td>\n",
       "      <td>originally gave this a 2 star but I think it o...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>5.9.0.2</td>\n",
       "      <td>2021-02-04 05:35:28</td>\n",
       "      <td>We are unaware of any issues with setting remi...</td>\n",
       "      <td>2021-02-04 09:08:06</td>\n",
       "      <td>most_relevant</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewId             userName  \\\n",
       "0  gp:AOqpTOH5OkwJH-nRT4nopD_JNTIYpWs1xWzOsFE-pn7...        Charles Green   \n",
       "1  gp:AOqpTOH2VEhd1ldAR1zxGzjJEIa37fCBgY9S3sqe_TE...  Matt Van Der Schyff   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "1  https://play-lh.googleusercontent.com/-sMd4wLr...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Ugh! After years of using this app, I am so ve...      1              3   \n",
       "1  originally gave this a 2 star but I think it o...      1             72   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0              5.9.0.2  2021-02-10 16:21:44   \n",
       "1              5.9.0.2  2021-02-04 05:35:28   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0  90% of the app is completely free, including a...  2021-02-11 09:29:42   \n",
       "1  We are unaware of any issues with setting remi...  2021-02-04 09:08:06   \n",
       "\n",
       "       sortOrder      appId  sentiment  \n",
       "0  most_relevant  com.anydo          0  \n",
       "1  most_relevant  com.anydo          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reviews1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('reviews1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.sentiment)\n",
    "#0: negative\n",
    "#1 : neutral\n",
    "#2: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing to use BERT LM fine tuned to text classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f0d8074974f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "print(tokenizer.sep_token , tokenizer.sep_token_id)\n",
    "print(tokenizer.cls_token , tokenizer.cls_token_id)\n",
    "print(tokenizer.pad_token , tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose the length of the sequence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1d05024e2c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokens_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtokens_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokens_length = []\n",
    "for content in df.content : \n",
    "    tokens = tokenizer.tokenize(content)\n",
    "    tokens_length.append(len(tokens))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fbd247daa00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(tokens_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self\n",
    "                 ,n_filters, \n",
    "                 filter_sizes, \n",
    "                 output_dim, \n",
    "                 dropout):\n",
    "        \n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased' )\n",
    "        \n",
    "        embedding_dim = self.bert.config.hidden_size\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask ):\n",
    "        \n",
    "        outputs , pooled_output = self.bert(\n",
    "\n",
    "        input_ids=input_ids,\n",
    "\n",
    "        attention_mask=attention_mask , return_dict=False )\n",
    "\n",
    "        #output = self.drop(pooled_output)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = outputs.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-83083a07db7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_FILTERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFILTER_SIZES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDROPOUT\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(2, 768), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(4, 768), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(data['input_ids'] , data['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0278, -0.8858,  0.2483],\n",
       "        [ 0.0957, -1.1293,  0.7377],\n",
       "        [ 0.2427, -0.9011, -0.0612],\n",
       "        [ 0.0876, -1.5888,  0.0224],\n",
       "        [ 0.0720, -0.8853, -0.1656],\n",
       "        [ 0.0357, -0.6106,  0.1440],\n",
       "        [-0.0084, -1.6168,  0.2699],\n",
       "        [ 0.5370, -0.3654, -0.0395]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(2, 768), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(4, 768), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = model.bert(data['input_ids'] , data['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 160, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 160, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].unsqueeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnTextClassifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ==> we can see that we have the distribution between 0 and 128 length so we are going to choose 128as a max length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset , DataLoader\n",
    "class Sentiment_analysis (Dataset) : \n",
    "    \n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "\n",
    "        self.reviews = reviews\n",
    "\n",
    "        self.targets = targets\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        review = str(self.reviews[item])\n",
    "\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "\n",
    "          review,\n",
    "\n",
    "          add_special_tokens=True,\n",
    "\n",
    "          max_length=self.max_len,\n",
    "\n",
    "          return_token_type_ids=False,\n",
    "\n",
    "          pad_to_max_length=True,\n",
    "\n",
    "          return_attention_mask=True,\n",
    "\n",
    "          return_tensors='pt',\n",
    "\n",
    "        )\n",
    "\n",
    "        return {'review_text': review,\n",
    "\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    }\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Sentiment_analysis(df.content , df.sentiment , tokenizer , 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sentiment_analysis at 0x7fbd01f0c580>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 160 \n",
    "batch_size = 8 \n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    ds = Sentiment_analysis(\n",
    "\n",
    "        reviews=df.content.to_numpy(),\n",
    "\n",
    "        targets=df.sentiment.to_numpy(),\n",
    "\n",
    "        tokenizer=tokenizer,\n",
    "\n",
    "        max_len=max_len)\n",
    "        \n",
    "    return DataLoader(ds,batch_size=batch_size,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train , data_test ,  = train_test_split(df , test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader =  create_data_loader(data_train , tokenizer , max_length , batch_size)\n",
    "test_data_loader =  create_data_loader(data_test , tokenizer , max_length , batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fbd01f0cdc0>\n"
     ]
    }
   ],
   "source": [
    "print(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/imagedpt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2149: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 160])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start building a classifier with bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel , BertForPreTraining\n",
    "from torch import nn\n",
    "import  torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_classifier(nn.Module) :\n",
    "    def __init__(self, n_classes):\n",
    "\n",
    "        super(sentiment_classifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased' )\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask ):\n",
    "        \n",
    "        _, pooled_output = self.bert(\n",
    "\n",
    "        input_ids=input_ids,\n",
    "\n",
    "        attention_mask=attention_mask , return_dict=False )\n",
    "\n",
    "        output = self.drop(pooled_output)\n",
    "\n",
    "        return self.out(output)\n",
    "    \n",
    "    def save (self, path) : \n",
    "        torch.save(self, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sentiment_classifier(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = data['input_ids']\n",
    "attention_mask = data['attention_mask']\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = model(input_ids = input_ids , attention_mask = attention_mask)\n",
    "preds_prob = torch.max(outputs , dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(outputs , dim = -1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , preds =  torch.max(outputs , dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(outputs , target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize our classifiers' layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import  torch.nn.functional as F\n",
    "outputs = F.softmax(model(input_ids, attention_mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "from torch.optim import AdamW\n",
    "from  transformers import get_linear_schedule_with_warmup\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    train_data_loader, \n",
    "    loss, \n",
    "    scheduler, \n",
    "    n_exemples\n",
    "    \n",
    ") : \n",
    "    losses = [] \n",
    "    correct_predictions = 0\n",
    "    model.train() \n",
    "    for  d in train_data_loader : \n",
    "        input_ids = d['input_ids'] \n",
    "        attention_mask = d['attention_mask']\n",
    "        targets = d['targets']\n",
    "        outputs = model( input_ids = input_ids , \n",
    "                       attention_mask = attention_mask) \n",
    "        _ , preds =  torch.max(outputs , dim = 1) \n",
    "        loss = loss_fn(outputs , targets )\n",
    "        losses.append(loss.item()) \n",
    "        correct_predictions += torch.sum(targets== preds)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "    return correct_predictions/n_exemples , np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch(model , data , loss_fn , scheduler , len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model( model, \n",
    "              dataloader , \n",
    "              loss_fn , \n",
    "              n_exemple) : \n",
    "    model.eval() \n",
    "    correct_prediciton = 0 \n",
    "    \n",
    "    for d in train_data_loader : \n",
    "        input_ids = d['input_ids'] \n",
    "        attention_mask = d['attention_mask']\n",
    "        targets = d['targets']\n",
    "        outputs = model( input_ids = input_ids , \n",
    "                       attention_mask = attention_mask) \n",
    "        _ , preds =  torch.max(outputs , dim = 1) \n",
    "        loss = loss_fn(outputs , targets )\n",
    "        losses.append(loss.item()) \n",
    "        correct_predictions += torch.sum(targets== preds)\n",
    "        \n",
    "    return correct_predictions.double()/n_exemple , np.mean(losses)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch in range (EPOCHS) : \n",
    "    train_acc, train_loss = train_epoch(\n",
    "\n",
    "    model,\n",
    "\n",
    "    train_data_loader,\n",
    "\n",
    "    loss_fn,\n",
    "\n",
    "    optimizer,\n",
    "\n",
    "    scheduler,\n",
    "\n",
    "    len(train_data_loader) )\n",
    "    \n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, text_loss = eval_model(\n",
    "\n",
    "    model,\n",
    "\n",
    "    test_data_loader,\n",
    "\n",
    "    loss_fn,\n",
    "\n",
    "    len(df_test)\n",
    "  )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn \n",
    "from transformers import BertModel , BertTokenizer\n",
    "\n",
    "class sentiment_analysis (nn.Module) : \n",
    "\n",
    "    def __init__(self, name_model,  n_class) : \n",
    "        super(sentiment_analysis, self).__init__()\n",
    "        self.name_model = name_model\n",
    "        self.bert = BertModel.from_pretrained(self.name_model)\n",
    "        self.drop = nn.Dropout(p=0.3) \n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, n_class)\n",
    "\n",
    "    def forward (self , input_ids, attention_mask) : \n",
    "        _ , pooled  = self.bert(input_ids  = input_ids , \n",
    "                                attention_mask = attention_mask, \n",
    "                                return_dict=False)\n",
    "        output = self.drop(pooled) \n",
    "        out = self.linear(output)\n",
    "        return out\n",
    "    \n",
    "    def save (self, path) : \n",
    "        self.save(path)\n",
    "\n",
    "    def load_tokenizer (self) : \n",
    "        tokenizer = BertTokenizer.from_pretrained(self.name_model)\n",
    "        return tokenizer\n",
    "\n",
    "\n",
    "    def predict (self , input_ids , attention_mask) : \n",
    "        self.eval()\n",
    "        preds = torch.max(self (input_ids = input_ids , attention_mask = attention_mask)[1] , dim = -1 ) \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sentiment_analysis ('bert-base-cased', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(input_ids = input_ids , attention_mask= attention_mask )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model (input_ids = input_ids , attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(p , targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "d = torch.tensor([1,1.6,99])\n",
    "torch.zeros(3).add(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions (model, dataloader) : \n",
    "    review_text = list()\n",
    "    predictions = list() \n",
    "    prediction_prob = [] \n",
    "    targets_list = []\n",
    "    for d in dataloader : \n",
    "        text = d['review_text']\n",
    "        input_ids = d['input_ids']\n",
    "        attention_mask = d['attention_mask']\n",
    "        targets = d['targets']\n",
    "        outputs  = model( input_ids =  input_ids , attention_mask = attention_mask)\n",
    "        _, preds  = torch.max( outputs , dim =1 ) \n",
    "        \n",
    "        review_text.extend(text) \n",
    "        targets_list.extend(targets)\n",
    "        _, pred = torch.max(outputs , dim = 1) \n",
    "        predictions.extend(preds) \n",
    "        prediction_prob.extend(outputs)\n",
    "        \n",
    "    predictions = torch.stack(predictions) \n",
    "    prediction_prob = torch.stack(prediction_prob)\n",
    "    targets_list = torch.stack(targets_list)\n",
    "    review_text = torch.stack(review_text)\n",
    "    return predictions, targets_list , review_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = sentiment_classifier(3)\n",
    "model.save_pretrained('m')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_acc , test_loss = eval_model(model , test_data_loader , loss_fn , len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets_list , review_text = get_predictions(model , test_data_loader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
